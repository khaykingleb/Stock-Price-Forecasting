{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Копия блокнота \"new.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Price Forecasting"
      ],
      "metadata": {
        "id": "On0KjyI58HDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conventional time series forecasting models have been widely used to construct predictions, such as the ARIMA models. Nevertheless, such models can perform quite poorly on financial data since financial markets are regarded as non-linear dynamic systems.\n",
        "\n",
        "So, we introduce recurrent neural networks (RNNs) that can learn complex dimensionality of the financial time series, which is essential to improving prediction performance. \n",
        "\n",
        "However, neural networks have a problem choosing parameters for the model, and solely the user's experience mostly determines them. To cope with this problem, metaheuristic optimization is considered such as particle swarm optimization, genetic algorithm, and so forth.\n",
        "\n",
        "The purpose of this notebook is to construct GA-optimized RNNs, namely LSTM and GRU networks, and compare their performance to the ARIMA model's forecast used as a benchmark. \n",
        "\n",
        "In addition, we want to test whether technical indicators are helpful for financial time series forecasting as additional features, as a RNN architecture allows us to use a multivariate time series. "
      ],
      "metadata": {
        "id": "Ahj8xcwD7jKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "vmEkaYp98Tce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install `sktime` package to work with ARIMA models and reload the notebook."
      ],
      "metadata": {
        "id": "8JnD8b0sUaWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pip install sktime[all_extras]"
      ],
      "outputs": [],
      "metadata": {
        "id": "aJP7Z8BEIkfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download necessary libraries:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pylab import rcParams\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "    \"font.family\": \"DejaVu Sans\",\n",
        "    \"font.sans-serif\": [\"Benton Sans\"]})\n",
        "    \n",
        "rcParams['figure.figsize'] = 10, 8\n",
        "\n",
        "theme_bw = 'theme_bw.mplstyle'\n",
        "plt.style.use(theme_bw)\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from genetic_algorithm import *\n",
        "\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {
        "id": "pzyKU-Tbj9Q7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xCJ40XmodBQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import datetime as dt\n",
        "\n",
        "# Use https://github.com/pydata/pandas-datareader/issues/868 to overcome the issue with pandas_datareader\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yfin\n",
        "yfin.pdr_override()"
      ],
      "outputs": [],
      "metadata": {
        "id": "dqMQuy0HK30Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Standard and Poor's 500, or simply the S\\&P 500, index is considered to compare the ARIMA as a benchmark model with metaheuristically optimized RNNs."
      ],
      "metadata": {
        "id": "zM9iUU1c9TMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ticker = \"SPY\"\n",
        "df = pdr.get_data_yahoo(ticker, dt.datetime(2000, 1,1,1), dt.datetime(2021, 1,1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "K94As9OiRAQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at the time series."
      ],
      "metadata": {
        "id": "Gtn4EhM5hsTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "plt.plot(df.index, df['Close'], alpha=0.8)\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14)\n",
        "plt.grid(False);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "NYKPkzn0hrWp",
        "outputId": "e89bb670-2f8e-4f38-938e-4562b995a5ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "del df['Adj Close']"
      ],
      "outputs": [],
      "metadata": {
        "id": "MKEeLkson3xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The research data for the index forecasting comes from 1 January 2000 to 1 January 2021 and is obtained from Yahoo Finance. Thus, an entire dataset has 5284 samples, or trading dates, in the form of daily closing prices. For the ARIMA model, we purely divide the dataset into training (90\\%) and test (10\\%) sets, while for globally optimized RNNs, we also separate the validation set (25\\%) from the training set in order to correctly choose the hyperparameters $\\Theta_{\\text{RNN}}$.\n"
      ],
      "metadata": {
        "id": "aIKN2eMZ9gy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_size = round(0.9 * df.shape[0])\n",
        "test_size = df.shape[0] - train_size\n",
        "val_size = round(0.25 * train_size)\n",
        "train_size = train_size - val_size"
      ],
      "outputs": [],
      "metadata": {
        "id": "jXX6yxlIJurM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_train = df['Close'][:val_size + train_size - 1]\n",
        "y_test = df['Close'][val_size + train_size - 1:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "sX3wi6YVJsUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several objective functions to measure forecast accuracy are used in the notebook, namely\n",
        "\n",
        "$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\text{RMSE}(\\hat y, X) = & \\ \\sqrt{\\frac{1}{T}\\sum\\limits _{t=1}^{T}( y_{t} -\\hat{y}( x_{t} ; w))^{2}} \\\\\n",
        "\\text{MAE}(\\hat{y}, X) = & \\ \\frac{1}{T}\\sum\\limits _{t=1}^{T} |y_{t} -\\hat{y}( x_{t} ; w)| \\\\\n",
        "\\text{SMAPE}(\\hat{y}, X) = & \\ \\frac{1}{T}\\sum _{t=1}^{T}\\dfrac{|y_{t} -\\hat{y}( x_{t} ; w) |}{( |y_{t} |+|\\hat{y}(x_{t};  w) |) /2} \\ \n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$\n",
        "\n",
        "and also one performance metric is used\n",
        "\n",
        "$$\n",
        "R^{2}\\left(\\hat{y}, X\\right) =1-\\frac{\\sum\\limits _{t=1}^{T}( y_{t} -\\hat{y}(x_{t} ; w))^{2}}{\\sum\\limits _{t=1}^{T}( y_{t} -\\overline{y})^{2}} ,\\ \\overline{y} =\\frac{1}{T}\\sum\\limits _{t=1}^{T} y_{t}\n",
        "$$"
      ],
      "metadata": {
        "id": "x2MOWa3c9xqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ARIMA"
      ],
      "metadata": {
        "id": "SlnKGNN_9DW8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import statsmodels.api as sm"
      ],
      "outputs": [],
      "metadata": {
        "id": "Sq8JuFvv9iDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoregressive integrated moving average, or ARIMA, model is the most widely used approach to time series forecasting. It attempts to capture the linear relationship between response variable $\\displaystyle y_{t}$ and its lagged values $y_{t-1}, \\dots, y_{t-k}$, that is information available earlier.\n",
        "\n",
        "If a series $\\{y_t\\}_{t=1}^T$ is assumed to be non-stationary, but a series $\\{\\Delta^d y_t\\}_{t=1}^T$, on the contrary, is stationary, we use $\\text{ARIMA}(p, d, q)$ process for $y_t$ with $d$-order of difference:\n",
        "$\n",
        "\\begin{equation*}\n",
        "\\begin{aligned}\n",
        "\\Delta ^{d} y_{t} = & \\ \\alpha +\\sum _{i=1}^{p} \\varphi _{i} \\Delta ^{d} y_{t-i} +\\sum _{i=1}^{q} \\psi _{i} \\varepsilon _{t-i} +\\varepsilon _{t} \\\\\n",
        "\\left( 1-\\sum _{i=1}^{p} \\varphi _{i} L^{i}\\right) \\Delta ^{d}y_{t} = & \\ \\alpha +\\left( 1+\\sum _{i=1}^{q} \\psi _{i} L^{i}\\right) \\varepsilon _{t} \\\\\n",
        "\\varphi _{p}( L) \\Delta ^{d}y_{t} = & \\ \\alpha +\\psi _{q}( L) \\varepsilon _{t}\n",
        "\\end{aligned}\n",
        "\\end{equation*}\n",
        "$"
      ],
      "metadata": {
        "id": "TSy992SJ7HXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this section, the Box-Jenkins methodology is used to construct the ARIMA model. At the first stage, we use a Box-Cox transformation to stabilize the variance of the series with $\\lambda = 0$:\n",
        "$$\n",
        "    \\tilde{y}_{t} ={\\displaystyle \\begin{cases}\n",
        "    \\ln y_{t} & \\lambda =0\\\\\n",
        "    \\dfrac{y_{t}^{\\lambda } -1}{\\lambda } , & \\lambda \\neq 0\n",
        "    \\end{cases}}\n",
        "$$\n",
        "where $y_t$ is a closing price of S\\&P500 index at time step $t$."
      ],
      "metadata": {
        "id": "Kf27TBKoAkdE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_new = df.copy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "i-5wouGTEO2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_new['Log_Close'] = np.log(df_new['Close'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dednt5llAuiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we identify whether our time series is stationary or not with the autocorrelation (ACF) and partial autocorrelation (PACF) functions. The former measures the linear relationship between the value of the index at the time step $t$ with that of lagged value at the time step $t-k$:\n",
        "\n",
        "$$\n",
        "\\hat{\\rho }_{k} =\\widehat{\\mathbb{Corr}}[y_{t}, y_{t-k}] =\\dfrac{\\sum\\limits _{t=k+1}^{T}(y_{t} -\\overline{y})(y_{t-k} -\\overline{y})}{\\sqrt{\\sum\\limits _{t=k+1}^{T}(y_{t} -\\overline{y})^{2}\\sum\\limits _{t=k+1}^{T}( y_{t-k} -\\overline{y})^{2}}},\\ \\overline{y} =\\dfrac{1}{T}\\sum _{t=1}^{T} y_{t},\\ 0\\leqslant k\\leqslant T-1 \n",
        "$$\n",
        "\n",
        "Whereas the latter is a <<pure>> correlation, noted $\\beta _{k}$, that can be obtained from the $\\text{AR(k)}$ process:\n",
        "\n",
        "$$\n",
        "y_{t} =\\beta _{0} + \\beta_{1} y_{t-1} +  \\dots + \\beta _{k} y_{t-k} +\\varepsilon _{t}\n",
        "$$"
      ],
      "metadata": {
        "id": "m734V-Rh-Vcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig = plt.figure(figsize=(14, 8))\n",
        "\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df_new['Log_Close'], lags=20, ax=ax1)\n",
        "ax1.xaxis.set_ticks_position('bottom')\n",
        "ax1.grid(False);\n",
        "fig.tight_layout();\n",
        "\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df_new['Log_Close'], lags=20, ax=ax2)\n",
        "ax2.xaxis.set_ticks_position('bottom')\n",
        "ax2.grid(False)\n",
        "fig.tight_layout();"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "UlGFRRa3_9tY",
        "outputId": "a4af616f-0d15-4319-9e49-fe437425fbc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observe, the time series is clearly not stationary. Hence, we conclude that differencing is required and use a first-order difference, $\\Delta y_t = y_t - y_{t-1}$."
      ],
      "metadata": {
        "id": "kXp4slmvDu7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_new['Log_Close_Shift_1'] = df_new['Log_Close'].shift()\n",
        "df_new[\"Log_Close_Diff_1\"] = df_new['Log_Close'] - df_new['Log_Close_Shift_1']\n",
        "df_new_a = df_new.dropna()\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'First-Order Differenced {ticker}', pad=14, fontsize=18, loc='left')\n",
        "plt.plot(df_new_a.index, df_new_a['Log_Close_Diff_1'], alpha=0.8)\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price, log scale', labelpad=10, fontsize=14)\n",
        "plt.grid(False);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "5gyEfsHZA93p",
        "outputId": "129ded12-a2df-4879-9c30-c1d5c9ab61f9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fig = plt.figure(figsize=(14, 8))\n",
        "\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df_new_a['Log_Close_Diff_1'], lags=20, ax=ax1)\n",
        "ax1.xaxis.set_ticks_position('bottom')\n",
        "ax1.grid(False)\n",
        "fig.tight_layout();\n",
        "\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df_new_a['Log_Close_Diff_1'], lags=20, ax=ax2)\n",
        "ax2.xaxis.set_ticks_position('bottom')\n",
        "ax2.grid(False)\n",
        "fig.tight_layout();"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "vmJBvY6XH3j9",
        "outputId": "82d67c58-f71d-4137-944e-8049ebc8ea2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After using differencing, it can easily be noted that the time series $\\{\\Delta y_t\\}_{t=1}^T$ appears to be stationary both in its mean and variance. \n",
        "\n",
        "Nevertheless, to determine more objectively whether additional differencing is required, an augmented Dickey-Fuller (ADF) test is used, which is a part of unit root tests. Our null hypothesis is that the time series is non-stationary, while the alternative hypothesis that it is stationary."
      ],
      "metadata": {
        "id": "EmiK9rGl-uZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "outputs": [],
      "metadata": {
        "id": "C856uXdpFP7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "result = adfuller(df_new_a['Log_Close_Diff_1'])\n",
        "\n",
        "print(f'ADF Statistic: {result[0]:.6}')\n",
        "print(f'p-value: {result[1]:.3}')\n",
        "print('Critical Values:')\n",
        "\n",
        "for key, value in result[4].items():\n",
        "\tprint('\\t%s: %.3f' % (key, value))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrnk9hD_Fby9",
        "outputId": "c73cb101-353f-48ac-97ea-f9887280f363"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our data, the ADF statistic is $-13.507$ and its p-value is $2.9\\mathrm{e}$-$25$. Thus, we fail to accept the null hypothesis and conclude that the series is stationary."
      ],
      "metadata": {
        "id": "NvWwA6jKGKwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows us to choose a number of $p$ AR and $q$ MA lags for the ARIMA model. For that we examine the stationary first-order differenced time\n",
        "series and propose several models. The best model is then chosen by the Akaike (AIC), corrected Akaike (AICc), and Bayes (BIC) information criteria:\n",
        "\n",
        "$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\text{AIC} = & \\ 2n - 2\\ln\\mathcal{L} \\\\\n",
        "\\text{AICc} = & \\ AIC+\\dfrac{2n( 1+n)}{T-s-n-1} \\\\ \n",
        "\\text{BIC} = & \\ n\\ln( T-s) -2\\ln\\mathcal{L}, \\ s=\\max(p_{max}, q_{max}) \\\\ \n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$\n",
        "\n",
        "where $n$ is a number of model parameters and $\\mathcal{L}$ is likelihood.\n",
        "\n",
        "However, in our case, we just can use the automatic ARIMA implemented in Python, which itself selects the correct number of lags by minimizing the above-noted information criteria."
      ],
      "metadata": {
        "id": "1cUjH0bJ_W20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sktime.forecasting.arima import ARIMA, AutoARIMA\n",
        "from sktime.forecasting.base import ForecastingHorizon"
      ],
      "outputs": [],
      "metadata": {
        "id": "vbxS71EEIcbZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "auto_arima = AutoARIMA(start_p=1, d=1, start_q=0, \n",
        "                       max_p=10, max_d=2, max_q=10, \n",
        "                       start_P=0, D=0, start_Q=0, \n",
        "                       max_P=0, max_D=0, max_Q=0, \n",
        "                       suppress_warnings=True, \n",
        "                       stepwise=False, n_jobs=-1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2xar605wJDfH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_ts_2 = pd.Series(data=y_train.values, index=pd.PeriodIndex(y_train.index, freq='D'))\n",
        "auto_arima.fit(train_ts_2);"
      ],
      "outputs": [],
      "metadata": {
        "id": "AbJPlSywSpSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_ts_2 = pd.Series(data=y_test.values, index=pd.PeriodIndex(y_test.index, freq='D'))\n",
        "fh = ForecastingHorizon(test_ts_2.index, is_relative=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5G3CI6C4ShWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we assume the first-order differencing, $\\Delta y_{t} =y_{t} -y_{t-1}$, then the point forecast for the ARIMA(p, 1, q) model is\n",
        "$\n",
        "\\begin{equation*}\n",
        "\\begin{aligned}\n",
        "\\Delta \\hat y_t = & \\ \\hat \\alpha + \\hat \\varphi_{1}\\Delta y_{t-1} + \\dots + \\hat \\varphi_{p}\\Delta y_{t-p} + \\varepsilon _{t} + \\hat \\psi_1 \\varepsilon _{t-1} + \\dots + \\hat \\psi_q \\varepsilon_{t-q} \\\\\n",
        "\\hat y_t = & \\ \\hat \\alpha + (\\hat\\varphi_1 + 1)y_{t-1} - (\\hat\\varphi_1 - \\hat\\varphi_2)y_{t-2} - \\dots - (\\hat\\varphi_{p-1} - \\hat\\varphi_p)y_{t-p} - \\hat \\varphi_p y_{t-p-1} + \\\\\n",
        " & \\ \\ \\ + \\varepsilon _{t} + \\hat \\psi_1 \\varepsilon _{t-1} + \\dots + \\hat \\psi_q \\varepsilon_{t-q}\n",
        "\\end{aligned}\n",
        "\\end{equation*}\n",
        "$\n",
        "\n",
        "Then $95$-\\% forcast interval is \n",
        "$$\n",
        "\\left(\\hat y_t - 1.96\\sqrt{\\mathbb{Var}(\\hat y_t)}, \\hat y_t + 1.96\\sqrt{\\mathbb{Var}(\\hat y_t)} \\right)\n",
        "$$"
      ],
      "metadata": {
        "id": "QQrsnDad8okU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred, y_intervals = auto_arima.predict(fh, return_pred_int=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3M_HVoqfR1Y6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'{ticker}', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index[:train_size+val_size], df['Close'][:train_size+val_size], \n",
        "         label='Train', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[train_size+val_size:], df['Close'][train_size+val_size:], \n",
        "         label='Test', alpha=0.8)\n",
        "\n",
        "ci_upper = y_intervals['upper'] - y_pred\n",
        "ci_lower = y_pred - y_intervals['lower']\n",
        "\n",
        "plt.plot(df.index[train_size+val_size:], y_pred, label='Pred', color='orange', alpha=0.8)\n",
        "\n",
        "plt.fill_between(df.index[train_size+val_size:], (y_pred-ci_lower), (y_pred+ci_upper), color='orange', alpha=0.1)\n",
        "\n",
        "plt.grid(False)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "1OpYU7K3V4d1",
        "outputId": "1545d105-b0e1-4f50-aa66-33535a8327e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "outputs": [],
      "metadata": {
        "id": "C8njwEXKijih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f'Test RMSE = {np.sqrt(sum((y_pred.values - y_test.values) ** 2)):.6}')\n",
        "print(f'Test MAE = {sum(np.abs(y_pred.values - y_test.values)):.6}')\n",
        "smape_test = 100 / len(y_pred.values) * np.sum(2 * np.abs(y_pred.values - y_test.values) / (np.abs(y_pred.values) + np.abs(y_test.values)))\n",
        "print(f'Test SMAPE = {smape_test:.4}')\n",
        "print(f'Test R_sq = {r2_score(y_test.values, y_pred.values):.2}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3g1RGpOYLVj",
        "outputId": "6f05c81d-5bb0-479b-fef9-e2fb1263d061"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, to assure that our model is adequate, we investigate if a series of the forecast errors can be considered as a white noise. To check that, the Ljung-Box test is used, where the null hypothesis assumes there is no remaining residual autocorrelation at lags 1 to $k$, while the alternative hypothesis assumes that at least one of the autocorelations is non-zero:\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "H_{0} : & \\rho _{1} =\\dotsc =\\rho _{k} =0\\\\\n",
        "H_{a} : & \\exists \\rho _{i} \\neq 0, \\ i \\in \\{1, \\dots, k\\}\n",
        "\\end{cases}\n",
        "$$"
      ],
      "metadata": {
        "id": "2gG1ps01_zm3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from statsmodels.stats.diagnostic import acorr_ljungbox"
      ],
      "outputs": [],
      "metadata": {
        "id": "ymfnew5W0ARW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "residuals = y_test.values - y_pred.values\n",
        "acorr_ljungbox(residuals, lags=10, return_df=True)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "TZ7e3ABw0Dzd",
        "outputId": "8c4b44ca-7dbd-48a1-8e30-3e8bf7dc3fe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Ljung-Box statistic has the form of $Q_{obs} = T(T+2)\\sum_{s=1}^{k}\\dfrac{\\hat{\\rho }_{s}^{2}}{T-s}  \\stackrel{H_0}{\\sim} \\chi ^{2}( k)$, where $k$ is a number of lags being tested. For our data, considering 10 lags the Ljung-Box statistic is equal to $4354.6$ with p-value of $0$. Thus, the null hypothesis is rejected and we assume that there is a significant residual autocorrelation. Hence, our model is not fully adequate, and a different model should be considered."
      ],
      "metadata": {
        "id": "XTUc6cTtAB1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that the ARIMA model has no significant performance. Hence, the GA-optimized recurrent network, or simply GA-RNN, with 14 look-back periods is proposed."
      ],
      "metadata": {
        "id": "WmNWa4dhPMqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "6eJ4-jXwkauH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the RNN architecture, we can add additional features into our dataset, namely trading volume for the S\\&P500 index and its technical indicators, such as 14-day simple and weighted moving averages, 200-day exponential moving average, relative strength index, and bollinger bands. So, we consider models: (GA-)LSTM and (GA-)GRU that take only a series of closing prices as an input, plus (GA-)LSTM-TI and (GA-)GRU-TI that take a multivariate series with technical indicators."
      ],
      "metadata": {
        "id": "2Aqc5uqNBL3F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import technical_indicators as ti"
      ],
      "outputs": [],
      "metadata": {
        "id": "eAUz75XEkdBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df['SMA(10)'] = ti.simple_moving_average(df, 10)\n",
        "df['WMA(10)'] = ti.weighted_moving_average(df, 10)\n",
        "df['EMA(200)'] = ti.weighted_moving_average(df, 10)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2i7VKkk-mLrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rsi = ti.relative_strength_index(df, 14)\n",
        "\n",
        "#k_percent, d_percent = ti.stochastic_oscillator(df)\n",
        "low_bb, high_bb = ti.bollinger_bands(df)\n",
        "macd, macd_signal, macd_difference = ti.moving_average_convergence_divergence(df)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6huZLQt0mxaf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df['Above_SMA(10)'] = np.where(df['Close'] > df['SMA(10)'], 1, 0)\n",
        "df['Above_WMA(10)'] = np.where(df['Close'] > df['WMA(10)'], 1, 0)\n",
        "df['Above_EMA(200)'] = np.where(df['Close'] > df['EMA(200)'], 1, 0)\n",
        "\n",
        "df['Oversold_RSI(14)'] = np.where(rsi < 30, 1, 0)\n",
        "df['Overbought_RSI(14)'] = np.where(rsi > 70, 1, 0)\n",
        "df['Oversold_Bollinger'] = np.where(df['Close'] < low_bb, 1, 0)\n",
        "df['Overbought_Bollinger'] = np.where(df['Close'] > high_bb, 1, 0)"
      ],
      "outputs": [],
      "metadata": {
        "id": "j4QVdwQ8DHmj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.dropna(inplace=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jL0M7BAcjr7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "P_SHs7S-CPu4",
        "outputId": "2060f5e7-2360-42c0-9a73-c7c1139d4b35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.describe()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "IWixeBfjuLsj",
        "outputId": "1b3ac31e-d188-4849-e612-de198cd4099a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to that, we introduce dummy variables that are considered to be buy and sell signals. They are supposed to help the (GA-)RNN-TI models predict the right closing price movement. Let $i \\in \\{\\text{SMA}, \\text{WMA}, \\text{EMA}\\}$ and $j \\in \\{\\text{RSI}, \\text{BB}\\}$, then  dummy variables can be written as\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "D^{\\text{below}}_{it} = & \\  {\\displaystyle \\begin{cases}\n",
        "    1, &  \\text{closing price is below $n$-day indicator $i$ at time $t$ }\\\\\n",
        "    0, & \\text{otherwise} \n",
        "    \\end{cases}}\\\\\n",
        "D^{\\text{above}}_{it} = & \\ {\\displaystyle \\begin{cases}\n",
        "    1, &  \\text{closing price is above $n$-day indicator $i$ at time $t$ }\\\\\n",
        "    0, & \\text{otherwise} \n",
        "    \\end{cases}}\\\\\n",
        "D^{\\text{oversold}}_{jt} = & \\  {\\displaystyle \\begin{cases}\n",
        "1, &  \\text{$n$-day indicator $j$ at time $t$ is lower than $30$}\\\\\n",
        "0, & \\text{otherwise} \n",
        "\\end{cases}}  \\\\\n",
        "D^{\\text{overbought}}_{jt} = & \\  {\\displaystyle \\begin{cases}\n",
        "    1, &  \\text{$n$-day indicator $j$ at time $t$ is greater than $70$}\\\\\n",
        "    0, & \\text{otherwise} \n",
        "    \\end{cases}}  \\\\\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "The indicator variables $D^{\\text{oversold}}_{jt}$ and $D^{\\text{overbought}}_{jt}$ are depicted below."
      ],
      "metadata": {
        "id": "O9SsA2VhPfyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "buy_signal_rsi = np.where(df['Oversold_RSI(14)'].to_numpy() == 1, df['Close'], np.nan)\n",
        "sell_signal_rsi = np.where(df['Overbought_RSI(14)'].to_numpy() == 1, df['Close'], np.nan)\n",
        "\n",
        "buy_signal_bb = np.where(df['Oversold_Bollinger'].to_numpy() == 1, df['Close'], np.nan)\n",
        "sell_signal_bb = np.where(df['Overbought_Bollinger'].to_numpy() == 1, df['Close'], np.nan)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PtmWYZoWeMeQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'RSI Singnal Chart for {ticker}', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], alpha=0.8)\n",
        "plt.scatter(df.index, buy_signal_rsi, label='Buy', marker='^', color='#66cdaa')\n",
        "plt.scatter(df.index, sell_signal_rsi, label='Sell', marker='v', color='#407294')\n",
        "\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14)\n",
        "plt.grid(False)\n",
        "plt.legend();"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "GbiPp2-CeEHd",
        "outputId": "0cb907fe-fd4d-41a4-dc5d-5ba9c174b094"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'Bollinger Bands Chart for {ticker}', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], alpha=0.8)\n",
        "plt.scatter(df.index, buy_signal_bb, label='Buy', marker='^', color='#66cdaa')\n",
        "plt.scatter(df.index, sell_signal_bb, label='Sell', marker='v', color='#407294')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14)\n",
        "plt.legend();"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "ZG7SkLWygr5f",
        "outputId": "ed095eef-7f6f-4f0e-efd7-ecbe02787555"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "TQY_Evtj-ywt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data on training, validation and test datasets to work with RNNs."
      ],
      "metadata": {
        "id": "eXomEej7OuNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Technical Indicators"
      ],
      "metadata": {
        "id": "NofMLfmlsEG3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_size = round(0.9 * df.shape[0])\n",
        "test_size = df.shape[0] - train_size\n",
        "val_size = round(0.25 * train_size)\n",
        "train_size = train_size - val_size"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nk80QhKgvc0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = df['Close'].to_numpy()"
      ],
      "outputs": [],
      "metadata": {
        "id": "OtGo6X8jsAlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating dummy variables, the time-series are min-max normalized, such that the preprocessed data lies between zero and one:\n",
        "\n",
        "$$\n",
        "    \\tilde{x}_{tj} = \\dfrac{x_{tj}-\\min_tx_{tj}}{\\max_tx_{tj}-\\min_tx_{tj}}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "PRa9eGoOB8Ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_without = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_preproc = torch.tensor(scaler_without.fit_transform(data.reshape(-1, 1))).reshape(1, -1).type(torch.Tensor)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fzKVeql3sAoZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "window_size = 15\n",
        "\n",
        "batch_windows = data_preproc.unfold(dimension=-1, size=window_size, step=1).reshape(-1, window_size, 1)\n",
        "    \n",
        "X_train_without = batch_windows[:val_size + train_size, :-1, :]\n",
        "X_test_without = batch_windows[val_size + train_size:, :-1]\n",
        "\n",
        "# Need predict the next value considering 14 lookback periods\n",
        "y_train_without = batch_windows[:val_size + train_size, -1, :]\n",
        "y_test_without = batch_windows[val_size + train_size:, -1, :]"
      ],
      "outputs": [],
      "metadata": {
        "id": "VCiayz5tr_2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Technical Indicators"
      ],
      "metadata": {
        "id": "nEVb1YZQvCQf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.columns"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFQFxNqwHFTy",
        "outputId": "86bacfa1-3650-4169-af97-0ac9a77e3241"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "columns_titles = ['Close', 'High', 'Low', 'Open', 'Volume', 'SMA(10)', 'WMA(10)',\n",
        "                  'EMA(200)', 'Oversold_RSI(14)', 'Overbought_RSI(14)',\n",
        "                  'Oversold_Bollinger', 'Overbought_Bollinger']\n",
        "df=df.reindex(columns=columns_titles)"
      ],
      "outputs": [],
      "metadata": {
        "id": "LvRjmK9YHQ7-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "GxXQmWrAlfWk",
        "outputId": "d7d030f1-266e-48df-d6e8-656b8a6e44b2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scaler_with = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_preproc = torch.tensor(scaler_with.fit_transform(df)).type(torch.Tensor)"
      ],
      "outputs": [],
      "metadata": {
        "id": "J2mjLq0qurgM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data_preproc_t = data_preproc.transpose(-2, -1)\n",
        "data_preproc_t"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tas2Oq9NJQOn",
        "outputId": "0c0731e8-9327-445d-e347-abd7589f6693"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "windows = []\n",
        "\n",
        "for i in range(data_preproc.shape[1]):\n",
        "    windows.append(data_preproc_t.unfold(dimension=-1, size=window_size, step=1)[i].reshape(-1, window_size, 1))"
      ],
      "outputs": [],
      "metadata": {
        "id": "UKAlfVHsJSpW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "batch_windows = torch.cat((windows), dim=2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "vJ_mgu78KGEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train_with = batch_windows[:val_size + train_size, :-1, :]\n",
        "X_test_with = batch_windows[val_size + train_size:, :-1]\n",
        "\n",
        "y_train_with = y_train_without\n",
        "y_test_with = y_test_without"
      ],
      "outputs": [],
      "metadata": {
        "id": "cGQYEunNxzMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index[:train_size+val_size], \n",
        "         df['Close'][:train_size+val_size], \n",
        "         label='Train', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[train_size+val_size:], \n",
        "         df['Close'][train_size+val_size:], \n",
        "         label='Test', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "PVHUNl7YMi2h",
        "outputId": "9b248f8e-4a21-4dfe-ac9b-0626c191fc77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "JnYAGFX-1RxR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_predictions(model, scaler, X_train, y_train, X_test, y_test):\n",
        "    model.eval()\n",
        "    y_pred_train = model(X_train.to(device))\n",
        "    y_pred_test = model(X_test.to(device))\n",
        "\n",
        "    y_pred_train = scaler.inverse_transform(y_pred_train.cpu().detach().numpy())\n",
        "    y_train = scaler.inverse_transform(y_train.cpu().detach().numpy())\n",
        "    \n",
        "    y_pred_test = scaler.inverse_transform(y_pred_test.cpu().detach().numpy())\n",
        "    y_test = scaler.inverse_transform(y_test.cpu().detach().numpy())\n",
        "\n",
        "    return y_pred_train, y_train, y_pred_test, y_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "aNfkxGzO2Yg_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def eval_losses(y_pred_train, y_true_train, y_pred_test, y_true_test):\n",
        "    print(f'Train RMSE = {np.sqrt(sum((y_pred_train - y_true_train) ** 2))[0]:.5}')\n",
        "    print(f'Train MAE = {sum(np.abs(y_pred_train - y_true_train))[0]:.5}')\n",
        "    smape_train = 100 / len(y_pred_train) * np.sum(2 * np.abs(y_pred_train - y_true_train) / (np.abs(y_pred_train) + np.abs(y_true_train)))\n",
        "    print(f'Train SMAPE = {smape_train:.5}\\n')\n",
        "\n",
        "    print(f'Test RMSE = {np.sqrt(sum((y_pred_test - y_true_test) ** 2))[0]:.5}')\n",
        "    print(f'Test MAE = {sum(np.abs(y_pred_test - y_true_test))[0]:.7}')\n",
        "    smape_test = 100 / len(y_pred_test) * np.sum(2 * np.abs(y_pred_test - y_true_test) / (np.abs(y_pred_test) + np.abs(y_true_test)))\n",
        "    print(f'Test SMAPE = {smape_test:.5}\\n')\n",
        "\n",
        "    print(f'R_sq = {r2_score(y_true_test, y_pred_test)}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "uGc0GaXIZfia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, reduction):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction=reduction)\n",
        "        \n",
        "    def forward(self, y_pred, y_true):\n",
        "        return torch.sqrt(self.mse(y_pred, y_true))"
      ],
      "outputs": [],
      "metadata": {
        "id": "qGAdCHpAcecs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "criterion = RMSELoss(reduction='mean')"
      ],
      "outputs": [],
      "metadata": {
        "id": "_T5SPi9Lzkv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNNs"
      ],
      "metadata": {
        "id": "LCAr9Inq24Di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A recurrent neural network (RNN) is a type of the ANN that is well-suited to time series $\\{y_t\\}_{t=1}^T$, since it is designed to work with sequence data.\n",
        "\n",
        "![](./../images/rnn_1.svg)\n",
        "\n",
        "\n",
        "Let us assume that we want to maximize the probability of a series $\\{y_t\\}_{t=1}^T$. Then the model would be written as \n",
        "$$\n",
        " p(y_1, \\dots, y_T) = \\prod_{t=1}^{T}p(y_t \\mid y_{t-1}, \\dots, y_1) \\rightarrow \\max \n",
        "$$\n",
        "\n",
        "In order to get $\\hat y_t$, there is a need to model the conditional probability given all previous values $\\hat y_{t-1}, \\dots, \\hat y_1$:\n",
        "\n",
        "$$\n",
        "\\hat y_t \\sim p(y_t \\mid \\hat y_{t-1}, \\dots, \\hat y_1)\n",
        "$$\n",
        "\n",
        "Note that to get the probability of $y_t$ we need to construct $t-1$\n",
        "sequential models. In such a case, the memory requirements grow exponentially with the time step $t$.\n",
        "\n",
        "However, instead of modeling this probability, we could use a latent variable $h_t$ called a hidden state, which stores all data it has seen so far:\n",
        "\n",
        "$$\n",
        "p(y_t \\mid \\hat y_{t-1}, \\dots, \\hat y_1) \\approx p(y_t \\mid h_{t-1}), \\ h_t = f(y_t, h_{t-1})\n",
        "$$\n",
        "\n",
        "The RNN uses this technique. It is the ANN with hidden states and is capable of conditioning the model on all previous values. Consider a multivariate time series $\\{(x_t, y_t)\\}_{t=1}^{T}$, $x_t \\in \\mathbb{R}^d \\ \\text{and} \\  y_t \\in \\mathbb{R}$, then the RNN has the following architecture:\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "h_{t} = & \\ f_{h}( W_{xh} x_{t} +W_{hh} h_{t-1} +b_{h}) \\\\\n",
        "\\hat{y}_{t} = & \\ f_{y}( W_{hy} h_{t} +b_{y}) \n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "where $h_{t}$ is hidden state and $\\hat y_t$ is output layer at the time step $t$, $W_{xh}$, $W_{hh}$, $W_{hy}$ are weights, $b_{h}, b_{y}$ are biases, and $f_{h}, f_{y}$ are activation functions.\n",
        "\n",
        "![](./../images/rnn_2.svg)"
      ],
      "metadata": {
        "id": "OP-D7ECN28eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropagation Through Time"
      ],
      "metadata": {
        "id": "kX1Upm6K3hYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a RNN model, we use backpropagation through time (BPTT), considering that now $L(y_{t}, \\hat{y}( x_{t}; w))=\\sum\\limits_{t=1}^{T} L_t(y_{t}, \\hat{y}_t( x_{t}; w))$.\n",
        "\n",
        "The derivatives of the loss function when there are no recurrent loops are computed straightforward:\n",
        "$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\dfrac{\\partial L}{\\partial b_{y}} = & \\  \\sum _{i=t}^{T}\\dfrac{\\partial L_{t}}{\\partial b_{y}} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial \\hat{y}_{t}}\\dfrac{\\partial \\hat{y}_{t}}{\\partial b_{y}} \\\\\n",
        "\\dfrac{\\partial L}{\\partial b_{h}} = & \\ \\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial b_{h}} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial h_{t}}\\dfrac{\\partial h_{t}}{\\partial b_{h}}\n",
        "\\dfrac{\\partial L}{\\partial W_{hy}} = \\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial W_{hy}} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial \\hat{y}_{t}}\\dfrac{\\partial \\hat{y}_{t}}{\\partial W_{hy}} \n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$\n",
        "\n",
        "However, it gets a little bit more complicated when there are recurrent loops. Let $W\\in \\{W_{xh} ,W_{hh}\\}$, then the derivatives of the loss function are written as follows\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\dfrac{\\partial L}{\\partial W} = & \\ \\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial W} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial \\hat{y}_{t}}\\dfrac{\\partial \\hat{y}_{t}}{\\partial h_{t}}\\dfrac{\\partial h_{t}}{\\partial W} = \\\\\n",
        "= & \\ \\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial \\hat{y}_{t}}\\dfrac{\\partial \\hat{y}_{t}}{\\partial h_{t}}\\left(\\dfrac{\\partial h_{t}}{\\partial W} +\\dfrac{\\partial h_{t}}{\\partial h_{t-1}}\\dfrac{\\partial h_{t-1}}{\\partial W} +\\dotsc +\\dfrac{\\partial h_{t}}{\\partial h_{t-1}}\\dfrac{\\partial h_{t-1}}{\\partial h_{t-2}} \\dotsc \\dfrac{\\partial h_{1}}{\\partial W}\\right) = \\\\\n",
        "= & \\ \\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial \\hat{y}_{t}}\\dfrac{\\partial \\hat{y}_{t}}{\\partial h_{t}}\\sum _{i=1}^{t}\\left(\\prod _{j=i+1}^{t}\\dfrac{\\partial h_{j}}{\\partial h_{j-1}}\\right)\\dfrac{\\partial h_{t}}{\\partial W}\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "Note that because a neuron $h\\in \\mathbb{R}^{q}$, each $\\partial h_{j} /\\partial h_{j-1}$ is the Jacobian matrix for $h$:\n",
        "$$\\dfrac{\\partial h_{j}}{\\partial h_{j-1}} =\\left(\\dfrac{\\partial h_{j}}{\\partial h_{j-1,1}} ,\\dotsc ,\\dfrac{\\partial h_{j}}{\\partial h_{j-1,q}}\\right) =\\begin{pmatrix}\n",
        "\\dfrac{\\partial h_{j,1}}{\\partial h_{j-1,1}} & \\dotsc  & \\dfrac{\\partial h_{j,1}}{\\partial h_{j-1,q}}\\\\\n",
        "\\vdots  & \\ddots  & \\vdots \\\\\n",
        "\\dfrac{\\partial h_{j,q}}{\\partial h_{j-1,1}} & \\dotsc  & \\dfrac{\\partial h_{j,q}}{\\partial h_{j-1,q}}\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "Now it can be inferred that the RNN has vanishing and exploding gradient problems:\n",
        "\n",
        "1. If $\\parallel \\dfrac{\\partial h_{j}}{\\partial h_{j-1}} \\parallel _{2} \\ < 1$, then the gradient is vanishing as the time step $t$ is becoming large. It means that $W^{new} = W^{old} -\\eta _{t}\\dfrac{\\partial L}{\\partial W} \\approx W^{old}$. To put it another way, our neural network stops learning.\n",
        "\n",
        "2. If $\\parallel \\dfrac{\\partial h_{j}}{\\partial h_{j-1}} \\parallel _{2}  \\ >1$, then the gradient is exploding as the time step $t$ is becoming large. Enormous updates to the weight during training reaches a bad parameter configuration and sometimes can cause a numerical overflow, i.e. NaNs.\n",
        "\n",
        "\n",
        "Given that, the RNN models often need help to stabilize their training. To solve the problem of exploding gradients, Pascanu et al. introduced a simple solution that clips gradients to a small\n",
        "number whenever they explode: \n",
        "\n",
        "$$\n",
        "    g = \\min\\left(1, \\dfrac{\\delta}{ \\parallel g \\parallel_2}  \\right)g\n",
        "$$\n",
        "\n",
        "where $\\delta$ is the threshold and $g = \\dfrac{\\partial L}{\\partial W}$. Alas, we still have the vanishing gradient problem."
      ],
      "metadata": {
        "id": "d-svZeBg3nLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "Z9lzNDLQ1T9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main problem of the RNN is that it struggles to preserve information over many time steps, since the hidden state is constantly being rewritten $h_t = f_{h}( W_{xh} x_{t} +W_{hh} h_{t-1} +b_{h})$. In order to cope with this, specific gates $\\Gamma = f( W_{x} x_{t} +W_{h} h_{t-1} +b)$ are introduced, where $W_{x}, W_{h}, b$ are weights specific to the gate and $f$ is an activation function. \n",
        "\n",
        "![](./../images/lstm.svg)\n",
        "\n",
        "Hochreiter and Schmidhuber proposed a RNN model with Long-Term Short-Term Memory (LSTM) blocks as a solution to the vanishing gradient problem. The LSTM block is designed to address long-term information preservation and short-term input skipping by using not only a hidden state $h_t$, but also a memory cell $c_t$ which is able to remember information over time. \n",
        "\n",
        "It has the following architecture:\n",
        "1. Hidden state $h_t$ and cell state $c_t$:\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "c_{t} = & \\ \\Gamma _{i} \\odot \\Gamma _{c} + \\Gamma _{f} \\odot c_{t-1} \\\\\n",
        "h_{t} = & \\ \\Gamma _{o} \\odot \\tanh( c_{t})\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "\n",
        "2. Input gate that decides what parts of the new cell content are written to cell\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\Gamma _{i} = & \\ \\sigma ( W_{xi} x_{t} +W_{hi} h_{t-1} +b_{i})\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "3. Cell gate that decides what new content to be written to the cell\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\Gamma _{c} = & \\ \\tanh( W_{xc} x_{t} +W_{hc} h_{t-1} +b_{c})\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "   \n",
        "\n",
        "4. Forget gate that decides what is kept and what is forgotten from previous cell state.\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\Gamma _{f} = & \\ \\sigma ( W_{xf} x_{t} +W_{hf} h_{t-1} +b_{f})\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "\n",
        "5. Output gate that decides what parts of cell are output to hidden state\n",
        "\n",
        "$$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\Gamma _{o} = & \\ \\sigma ( W_{xo} x_{t} +W_{ho} h_{t-1} +b_{o})\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$$\n",
        "\n",
        "\n",
        "Using BPTT, we can show that $\\displaystyle \\forall W \\in \\{W_{xi}, W_{hi}, W_{xf}, W_{hf}, W_{xc}, W_{hc}, W_{xo}, W_{ho}\\}$ the derivatives of the loss function are written as\n",
        "$$\\dfrac{\\partial L}{\\partial W} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial W} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial h_{t}}\\dfrac{\\partial h_{t}}{\\partial c_{t}}\\dfrac{\\partial c_{t}}{\\partial c_{t-1}} \\dotsc \\dfrac{\\partial c_{1}}{\\partial W} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial h_{t}}\\dfrac{\\partial h_{t}}{\\partial c_{t}}\\left(\\prod _{j=i+1}^{t}\\dfrac{\\partial c_{j}}{\\partial c_{j-1}}\\right)\\dfrac{\\partial c_{1}}{\\partial W}$$\n",
        "\n",
        "To solve the vanishing or exploding gradient problem, we need $\\parallel \\dfrac{\\partial c_{j}}{\\partial c_{j-1}} \\parallel _{2} \\ \\approx 1$. \n",
        "So, let us then expand the product expression:\n",
        "\n",
        "$\n",
        "\\begin{equation*} \n",
        "\\begin{aligned}\n",
        "\\dfrac{\\partial c_{j}}{\\partial c_{j-1}} = & \\ \\dfrac{\\partial }{\\partial c_{j-1}}( \\Gamma _{i} \\odot \\Gamma _{c} +\\Gamma _{f} \\odot c_{j-1}) =\\dfrac{\\partial }{\\partial c_{j-1}}( \\Gamma _{i} \\odot \\Gamma _{c}) +\\dfrac{\\partial }{\\partial c_{j-1}}( \\Gamma _{f} \\odot c_{j-1}) =\n",
        "\\\\\n",
        "= & \\ \\dfrac{\\partial \\Gamma _{i}}{\\partial c_{j-1}} \\Gamma _{c} +\\dfrac{\\partial \\Gamma _{c}}{\\partial c_{j-1}} \\Gamma _{i} +\\dfrac{\\partial \\Gamma _{f}}{\\partial c_{j-1}} c_{j-1} +\\Gamma _{f}\n",
        "\\end{aligned}\n",
        "\\end{equation*} \n",
        "$\n",
        "\n",
        "We can observe that LSTM's additive property enables us to balance the gradient values during BPTT:\n",
        "\n",
        "$$\\dfrac{\\partial L}{\\partial W} =\\sum _{t=1}^{T}\\dfrac{\\partial L_{t}}{\\partial h_{t}}\\dfrac{\\partial h_{t}}{\\partial c_{t}}\\left(\\prod _{j=i+1}^{t}\\left[\\dfrac{\\partial \\Gamma _{i}}{\\partial c_{j-1}} \\Gamma _{c} +\\dfrac{\\partial \\Gamma _{c}}{\\partial c_{j-1}} \\Gamma _{i} +\\dfrac{\\partial \\Gamma _{f}}{\\partial c_{j-1}} c_{j-1} +\\Gamma _{f}\\right]\\right)\\dfrac{\\partial c_{1}}{\\partial W}$$"
      ],
      "metadata": {
        "id": "ixfmVW3B0aFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without Technical Indicators"
      ],
      "metadata": {
        "id": "FO3fyA038PM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "\n",
        "lstm_model = LSTM()\n",
        "lstm_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrSlrUZa3DEm",
        "outputId": "5bc9d540-4bc3-459d-b32d-5c238f70609d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.01)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oQ6h_p5guVa2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_lstm_without, test_loss_lstm_without = \\\n",
        "    train(lstm_model, criterion, optimizer, device, X_train_without, y_train_without, \n",
        "           X_test_without, y_test_without, n_epochs=100)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_pwhMWQ3cqD3",
        "outputId": "7320239e-d8e4-43c3-c977-8a4dcf51eeff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_lstm_without, y_train_lstm_without, y_pred_test_lstm_without, y_test_lstm_without = \\\n",
        "    get_predictions(lstm_model, scaler_without, X_train_without, y_train_without, X_test_without, y_test_without)"
      ],
      "outputs": [],
      "metadata": {
        "id": "jVhzdDUk42Fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_lstm_without, y_train_lstm_without, \n",
        "            y_pred_test_lstm_without, y_test_lstm_without)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uILv-9BK5xm0",
        "outputId": "174d69ec-b87c-44f0-c64f-ae31d292b393"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'LSTM for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth', alpha=0.7)\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_lstm_without.ravel(), \n",
        "         label='Train prediction', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_lstm_without.ravel(), \n",
        "         label='Test prediction', color='#00A170', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "r_2OqrYZZ667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "c5b168fa-200f-4748-e9f0-284cf4755cc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With Technical Indicators"
      ],
      "metadata": {
        "id": "ovOcXJyP_QHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "lstm_model = LSTM(input_size=X_train_with.shape[2])\n",
        "lstm_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-WScsRrRnGG",
        "outputId": "319b88e4-9411-43f5-91a0-28eeb88b5a34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.01)"
      ],
      "outputs": [],
      "metadata": {
        "id": "geQ-z__MRnGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_lstm_with, test_loss_lstm_with = \\\n",
        "    train(lstm_model, criterion, optimizer, device, X_train_with, y_train_without,\n",
        "          X_test_with, y_test_without, n_epochs=100)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uwIkT2yPRnGH",
        "outputId": "c3d1958a-ac5b-4877-bb1d-fc7cca42720c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_lstm_with, y_train_lstm_with, y_pred_test_lstm_with, y_test_lstm_with = \\\n",
        "    get_predictions(lstm_model, scaler_without, X_train_with, y_train_with, X_test_with, y_test_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bMp_VkJvOcDb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_lstm_with, y_train_lstm_with, y_pred_test_lstm_with, \n",
        "            y_test_lstm_with)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1OKlWGEd5J5",
        "outputId": "d0d994f3-28f2-4c01-fb73-371d26b56aa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'LSTM-TI for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_lstm_with.ravel(), \n",
        "         label='Train prediction', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_lstm_with.ravel(), \n",
        "         label='Test prediction', color='#9BB7D4', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "zcYMYQwTSkd6",
        "outputId": "35ecda8f-a8d4-47cd-a7cb-d0692572bb6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gated Recurrent Units"
      ],
      "metadata": {
        "id": "q4RKnv7JqSdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cho et al. proposed in 2014 an alternative to the LSTM. It has only the hidden state $h_{t} =( 1- \\Gamma _{u}) \\odot \\Gamma _{n} +\\Gamma _{u} \\odot h_{t-1}$ with three gates which offers comparable performance to that of LSTM and is significantly faster to compute:\n",
        "\n",
        "1. Reset gate:\n",
        "$$\\Gamma _{r} =\\sigma ( W_{xr} x_{t} +W_{hr} h_{t-1} +b_{r})$$\n",
        "\n",
        "2. Update gate: \n",
        "$$ \\Gamma _{u} =\\sigma ( W_{xu} x_{t} +W_{hu} h_{t-1} +b_{u})$$\n",
        "\n",
        "3. New gate:\n",
        "$$\\Gamma _{n} =\\tanh( W_{xn} x_{t} +b_{xn} +\\Gamma _{r} \\odot  ( W_{hn} h_{t-1} +b_{hn}))$$\n"
      ],
      "metadata": {
        "id": "PJOh5PNu2Ge_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](./../images/gru.svg)"
      ],
      "metadata": {
        "id": "h3R9R0CJHQvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without Technical Indicators"
      ],
      "metadata": {
        "id": "88RJGK595SWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "gru_model = GRU()\n",
        "gru_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz0-0u8TsvIM",
        "outputId": "9f659e2e-f299-49c1-b35a-44152d619423"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.01)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qr5X-bmZuP5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_gru_without, test_loss_gru_without = \\\n",
        "    train(gru_model, criterion, optimizer, device, X_train_without, y_train_without, X_test_without, \n",
        "          y_test_without, n_epochs=100)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FxgSJTgDtIL3",
        "outputId": "212a897a-1215-43d3-f692-cc619f253c58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_gru_without, y_train_gru_without, y_pred_test_gru_without, y_test_gru_without = \\\n",
        "    get_predictions(gru_model, scaler_without, X_train_without, y_train_without, \n",
        "                    X_test_without, y_test_without)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Cp5KkTh829Oj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_gru_without, y_train_gru_without, y_pred_test_gru_without, \n",
        "            y_test_gru_without)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orqALJ2KzrXP",
        "outputId": "85fb02c4-10db-4bf1-9c38-dc552a68be6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'GRU for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_gru_without.ravel(), \n",
        "         label='Train prediction', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_gru_without.ravel(), \n",
        "         label='Test prediction', color='#EDD59E', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "2eM9v4q9usqz",
        "outputId": "cc7e44ed-f249-4cdf-c02c-073ebaa6356a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With Technical Indicators"
      ],
      "metadata": {
        "id": "oR2atyMJwAt2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "gru_model = GRU(input_size=X_train_with.shape[2])\n",
        "gru_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGk69hMX1Hje",
        "outputId": "15fe3899-9cfc-4fad-8b45-f41bd2ef7992"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.01)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PykgMmxl1Hjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_gru_with, test_loss_gru_with = \\\n",
        "    train(gru_model, criterion, optimizer, device, X_train_with, y_train_with, \n",
        "          X_test_with, y_test_with, n_epochs=100)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Yp1ZXV6Wuuoh",
        "outputId": "905e685e-ecce-4fb5-c34a-701dcd3c5283"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_gru_with, y_train_gru_with, y_pred_test_gru_with, y_test_gru_with = \\\n",
        "    get_predictions(gru_model, scaler_without, X_train_with, y_train_with, X_test_with, y_test_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zS0Y1cgR4q4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_gru_with, y_train_gru_with, y_pred_test_gru_with, \n",
        "            y_test_gru_with)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7vrwKeo4rVi",
        "outputId": "0603d3ec-80e3-4b9d-c10e-a8d94c535d55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'GRU-TI for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_gru_with.ravel(), \n",
        "         label='Train prediction', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_gru_with.ravel(), \n",
        "         label='Test prediction', color='#6B5876', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "3CHS03mNETn0",
        "outputId": "e24a1c61-565e-4dbc-b154-203724876a6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison"
      ],
      "metadata": {
        "id": "cqOv0Ba9Ef0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Train RMSE', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(np.log(train_loss_lstm_without), marker='D', markersize=4, label='LSTM', alpha=0.7, color='#00A170')\n",
        "plt.plot(np.log(train_loss_lstm_with), marker='o', markersize=4, label='LSTM-TI', alpha=0.7, color='#9BB7D4')\n",
        "plt.plot(np.log(train_loss_gru_without), marker='^', markersize=4, label='GRU', alpha=0.7, color='#EDD59E')\n",
        "plt.plot(np.log(train_loss_gru_with), marker='s', markersize=4, label='GRU-TI', alpha=0.7, color='#6B5876')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "\n",
        "plt.ylim(-4.6, 0.4)\n",
        "\n",
        "plt.ylabel('Loss, log scaled', labelpad=10, fontsize=14)\n",
        "plt.xlabel('Epoch', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "rSpmJliv4rqa",
        "outputId": "73e1aff8-9a52-4202-efd3-542ba2460046"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.title('Test RMSE', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(np.log(test_loss_lstm_without), marker='D', markersize=4, label='LSTM', alpha=0.7, color='#00A170')\n",
        "plt.plot(np.log(test_loss_lstm_with), marker='o', markersize=4, label='LSTM-TI', alpha=0.7, color='#9BB7D4')\n",
        "plt.plot(np.log(test_loss_gru_without), marker='^', markersize=4, label='GRU', alpha=0.7, color='#EDD59E')\n",
        "plt.plot(np.log(test_loss_gru_with), marker='s', markersize=4, label='GRU-TI', alpha=0.7, color='#6B5876')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "\n",
        "plt.ylim(-4.6, 0.4)\n",
        "\n",
        "plt.ylabel('Loss, log scaled', labelpad=10, fontsize=14)\n",
        "plt.xlabel('Epoch', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "ntgj_XDQd8vR",
        "outputId": "b8c2b474-2213-4027-eea4-d83bf9f42773"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metaheuristic Optimization"
      ],
      "metadata": {
        "id": "d4rUqEvxqNKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimal hyperparameters, $\\Theta$, of a RNN model that are set before training the neural network, such as a number of neurons and their size, are difficult to determine. Hence, we use a metaheuristic optimization technique to find a good approximation of the global minimum, in contrast to deterministic optimization methods that almost virtually find a local rather than a global optimum solution. "
      ],
      "metadata": {
        "id": "SVCnL7k21y_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Technicals"
      ],
      "metadata": {
        "id": "z8aCk9sbHRfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_without = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_preproc = torch.tensor(scaler_without.fit_transform(data.reshape(-1, 1))).reshape(1, -1).type(torch.Tensor)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Rjvrw_AaquS6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "batch_windows = data_preproc.unfold(dimension=-1, size=window_size, step=1).reshape(-1, window_size, 1)\n",
        "    \n",
        "X_train_without = batch_windows[:train_size, :-1, :]\n",
        "X_val_without = batch_windows[train_size:train_size+val_size, :-1]\n",
        "X_test_without = batch_windows[train_size+val_size:, :-1]\n",
        "\n",
        "# Need predict the next value considering 14 lookback periods\n",
        "y_train_without = batch_windows[:train_size, -1, :]\n",
        "y_val_without = batch_windows[train_size:train_size+val_size, -1, :]\n",
        "y_test_without = batch_windows[train_size+val_size:, -1, :]"
      ],
      "outputs": [],
      "metadata": {
        "id": "VjUKZ4VXquS6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index[:train_size], \n",
        "         df['Close'][:train_size], \n",
        "         label='Train', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[train_size:train_size+val_size], \n",
        "         df['Close'][train_size:train_size+val_size],\n",
        "         label='Validation', alpha=0.8)\n",
        "\n",
        "plt.plot(df.index[train_size+val_size:], \n",
        "         df['Close'][train_size+val_size:], \n",
        "         label='Test', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "6658UwaWMeKf",
        "outputId": "73044ab5-3903-4ab4-b025-c904bac1feb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Technicals"
      ],
      "metadata": {
        "id": "fQy4AVPJHVlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scaler_with = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_preproc = torch.tensor(scaler_with.fit_transform(df)).type(torch.Tensor)\n",
        "data_preproc_t = data_preproc.transpose(-2, -1)\n",
        "\n",
        "windows = []\n",
        "\n",
        "for i in range(data_preproc.shape[1]):\n",
        "    windows.append(data_preproc_t.unfold(dimension=-1, size=window_size, step=1)[i].reshape(-1, window_size, 1))\n",
        "\n",
        "batch_windows = torch.cat((windows), dim=2)\n",
        "\n",
        "X_train_with = batch_windows[:train_size, :-1, :]\n",
        "X_val_with = batch_windows[train_size:train_size+val_size, :-1]\n",
        "X_test_with = batch_windows[train_size+val_size:, :-1]\n",
        "\n",
        "# Need predict the next value considering 14 lookback periods\n",
        "y_train_with = y_train_without\n",
        "y_val_with = y_val_without\n",
        "y_test_with = y_test_without"
      ],
      "outputs": [],
      "metadata": {
        "id": "CSOxC7Y8HYLh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_val_with = batch_windows[train_size:train_size+val_size, :-1]"
      ],
      "outputs": [],
      "metadata": {
        "id": "jZygDf-NoT15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Genetic Algorithm"
      ],
      "metadata": {
        "id": "ZXXxtaKX8tky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genetic algorithm (GA) is a population-based metaheuristic optimization algorithm proposed by Holland (Holland, 1984). The GA imitates the process of natural evolution in solving an optimization problem by relying on biologically inspired operations such as natural selection, mutation, and crossover.\n",
        "\n",
        "![](./../images/ga_algorithm.svg)\n",
        "\n",
        "\n",
        "Let our population $ \\Theta$ has $\\displaystyle \\ell $ individuals with chromosomes $\\{\\theta_i\\}_{i=1}^\\ell$, as represented in the first figure, where a chromosome $\\theta_i \\in \\mathbb{R}^p$ is a set of $p$ hyperparameters, and a hyperparameter is called a gene. Then, the population at the time step $\\displaystyle k$ is written as follows:\n",
        "$$ \\Theta _{k} =\\left\\{\\theta _{i}^{( k)} \\mid \\left( \\theta _{i1}^{( k)} ,\\dotsc ,\\theta _{ip}^{( k)]}\\right) \\in \\mathbb{R}^{p}\\right\\}_{i=1}^{\\ell }$$\n",
        "\n",
        "![](./../images/ga_population.svg)\n",
        "\n",
        "Now let us look at the algorithm itself:\n",
        "\n",
        "1.   We randomly generate the first population of individuals: \n",
        "$$\\Theta_{0} =\\left\\{\\left(\\theta_{1}^{( 0)}, \\dotsc, \\theta_{\\ell}^{( 0)}\\right) \\in \\mathbb{R}^{\\ell\\times d} \\mid \\theta _{ij}^{( 0)} \\sim U(\\alpha, \\beta )\\right\\}$$\n",
        "\n",
        "2. Then assess the fitness of each individual. For this, we need to calculate the values of the objective function for each chromosome \n",
        "$$\\mathcal{L}_{k} =\\left\\{Q\\left( \\theta _{i}^{( k)}\\right)\\right\\}_{i=1}^{\\ell }$$\n",
        "and apply a transformation function\n",
        "$$\\sigma ( z) =\\dfrac{z-\\mathcal{L}_{k}^{worst}}{\\mathcal{L}_{k}^{best} -\\mathcal{L}_{k}^{worst}}$$\n",
        "such that its components lie between zero and one. For instance, if an individual $z$ has near-one value, it means that it has high fitness relative to other. Hence, we get the values of the fitness function of individuals $ \\mathcal {F}_{k} = \\left\\{\\sigma \\left(\\mathcal {L}_{k}\\left(\\theta^{(k)}_i\\right)\\right)\\right\\}_{i=1}^\\ell $.\n",
        "3. Select the most fitted $m$ individuals for further breeding. For this, we assume that an individual $\\xi$ is better fitted than an individual $\\eta$ if $\\mathcal{F}_{k}(\\xi)= \\sigma(Q(\\xi)) > \\sigma(Q(\\eta)) = \\mathcal{F}_{k}(\\eta)$. Then, we rank individuals in the current population according to their fitness values in descending order, that is from the most fitted to the less:\n",
        "$$\\mathcal{F}_{k}^{[ 1]} \\geqslant \\dotsc \\geqslant \\mathcal{F}_{k}^{[ m]} \\geqslant \\dotsc \\geqslant \\mathcal{F}_{k}^{[ \\ell ]}$$\n",
        "\n",
        "4. Crossover the fittest $m$ individuals with everyone else. This is how we spread the \"good\" genes throughout the population. By crossover we mean the operation of creating a new chromosome, wherein a part of the genes will be from the high fitted individual $\\displaystyle \\xi ^{( k)} \\in \\left\\{\\theta _{i}^{( k)}\\right\\}_{i=1}^{m}$ with the probability of \n",
        "$$\\displaystyle \\mathbb{P}\\left(\\left\\{ \\theta _{i}^{new} =\\xi ^{( k)}\\right\\}\\right) =\\dfrac{\\sigma \\left( Q\\left( \\xi ^{( k)}\\right)\\right)}{\\sigma \\left( Q\\left( \\xi ^{( k)}\\right)\\right) +\\sigma \\left( Q\\left( \\eta ^{( k)}\\right)\\right)}$$\n",
        "and of the genes will be from the less fitted individual $\\eta ^{( k)} \\in \\left\\{\\theta _{i}^{( k)}\\right\\}_{i=m+1}^{n}$ with the probability of \n",
        "\n",
        "$$\\mathbb{P}\\left(\\left\\{\\theta _{i}^{new} =\\eta ^{( k)}\\right\\}\\right) =\\dfrac{\\sigma \\left( Q\\left( \\eta ^{( k)}\\right)\\right)}{\\sigma \\left( Q\\left( \\xi ^{( k)}\\right)\\right) +\\sigma \\left( Q\\left( \\eta ^{( k)}\\right)\\right)}$$\n",
        " \n",
        "Thus, we get\n",
        "$$\\theta _{ij}^{new} =\\begin{cases} \\xi _{j}^{( k)}, & \\text{with} \\ \\mathbb{P}\\left(\\left\\{\\theta _{i}^{new} =\\xi ^{( k)}\\right\\}\\right)\\\\ \\eta _{j}^{( k)}, & \\text{with} \\ \\mathbb{P}\\left(\\left\\{\\theta _{i}^{new} =\\eta ^{( k)}\\right\\}\\right) \\end{cases} ,\\ i\\in ( m+1,\\dotsc ,n) ,\\ j\\in ( 1, \\dotsc, p)$$\n",
        "\n",
        "5. All individuals except the best in the current population, $ \\left\\{\\theta _ {i} ^ {(k)} \\right \\} _ {i = 2} ^ {\\ell} $, are mutated. The mutation changes an arbitrary number of genes in an individual's chromosome for other but rather close to the original value, so afterwards we get\n",
        "$$ \\Theta_{k+1} =\\left\\{\\theta _{1}^{( k)}\\right\\} \\cup \\left\\{\\theta _{i}^{( k)} \\mid \\theta _{ij}^{( k)} =\\theta _{ij}^{( k)} +\\varepsilon _{j}\\right\\}_{i=2}^{\\ell } $$\n",
        "\n",
        "6. Go to the step 2 until the stop criterion is met. For instance, it can be a reach of the maximum possible number of population evolutions."
      ],
      "metadata": {
        "id": "mcCIK8xFR9Ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we attempt to choose hyperparameters of our models, that is the correct number of hidden layers and training epochs, the hidden size of neurons, and the learning rate. For this reason, the genetic algorithm is used as a metaheuristic optimizer. Hence, we create a population with $150$ individuals—in our case, Adam optimized neural networks—with the mutation rate of $40\\%$ and $10$ meta epochs considered. Moreover, we select the $40$ most fitted individuals to crossover. \n",
        "\n",
        "\n",
        "![](images/ga_rnn.svg)\n",
        "\n",
        "\n",
        "\n",
        "Given that a number of hidden layers can range from $1$ to $15$, training epochs from $60$ to $300$, a hidden size from $8$ to $512$, and a learning rate from $0.001$ to $1$."
      ],
      "metadata": {
        "id": "SUetrvRdCQz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GA-LSTM"
      ],
      "metadata": {
        "id": "4450_3Hpouso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "# Here k is NOT a time step but m in the equations above! \n",
        "config = GeneticAlgorithmConfig(ell=150, k=40, num_epochs=10, mutation_rate=0.4)\n",
        "population = Population(config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "NocFltSkS9dk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer = GeneticAlgorithm(optimized_block='LSTM',criterion=criterion, \n",
        "                                population=population, config=config, \n",
        "                                device=device, verbose=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F09SkR3BqULN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer.fit(X_val_without, y_val_without)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "XPCmmwPuqeqX",
        "outputId": "c2df031c-2111-47ba-e021-d23800b7069c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "ga_lstm_model = LSTM(input_size=X_train_without.shape[2],\n",
        "                     hidden_size=ga_optimizer.population.best_indivdual.hidden_size,\n",
        "                     num_layers=ga_optimizer.population.best_indivdual.num_layers)\n",
        "ga_lstm_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "grGVwG8iBCyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfb1012-a653-4105-e4d9-4cc97c73fa1d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(ga_lstm_model.parameters(), \n",
        "                             lr=ga_optimizer.population.best_indivdual.learning_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fg4hwjvjBCyY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_ga_lstm_without, test_loss_ga_lstm_without = \\\n",
        "    train(ga_lstm_model, criterion, optimizer, device, \n",
        "          torch.vstack((X_train_without, X_val_without)), \n",
        "          torch.vstack((y_train_without, y_val_without)), \n",
        "          X_test_without, y_test_without, \n",
        "          n_epochs=ga_optimizer.population.best_indivdual.num_epochs_base)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4a9sbj3PBCya",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "7fbf2851-3cf7-4a94-fcd9-91eadb7ae360"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_ga_lstm_without, y_train, y_pred_test_ga_lstm_without, y_test = \\\n",
        "    get_predictions(ga_lstm_model, scaler_without, \n",
        "                    torch.vstack((X_train_without, X_val_without)),\n",
        "                    torch.vstack((y_train_without, y_val_without)), \n",
        "                    X_test_without, y_test_without)"
      ],
      "outputs": [],
      "metadata": {
        "id": "JExS9WpTB5v-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_ga_lstm_without, y_train, \n",
        "            y_pred_test_ga_lstm_without, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "LnfyuWIfB5v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446adb08-f3c1-4964-cbf7-a40353180824"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "plt.title(f'GA-LSTM for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth')\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], y_pred_train_ga_lstm_without.ravel(), label='Train prediction', alpha=0.8)\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], y_pred_test_ga_lstm_without.ravel(), label='Test prediction', color='#00A170', alpha=0.8)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "0MZaenwxB5v_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "344aa069-9997-400b-881e-0ed6b0b24128"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GA-LSTM-TI"
      ],
      "metadata": {
        "id": "qyRRUeCSneKa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "config = GeneticAlgorithmConfig(ell=150, k=40, num_epochs=10, mutation_rate=0.4)\n",
        "population = Population(config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eMwUg6nqneKm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer = GeneticAlgorithm(optimized_block='LSTM',criterion=criterion, \n",
        "                                population=population, config=config, \n",
        "                                device=device, verbose=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "H-qYlLflneKn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer.fit(X_val_with, y_val_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xr62_UoineKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b9f508a1-27c1-406c-bdee-673541b6bfe0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "ga_lstm_model = LSTM(input_size=X_train_with.shape[2],\n",
        "                     hidden_size=ga_optimizer.population.best_indivdual.hidden_size,\n",
        "                     num_layers=ga_optimizer.population.best_indivdual.num_layers)\n",
        "ga_lstm_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "TQFRKOFtneKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbd93dc-957a-47c4-838a-1bb3edca7f2a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(ga_lstm_model.parameters(), \n",
        "                             lr=ga_optimizer.population.best_indivdual.learning_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hv-wDnGuneKo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_ga_lstm_with, test_loss_ga_lstm_with = \\\n",
        "    train(ga_lstm_model, criterion, optimizer, device, \n",
        "          torch.vstack((X_train_with, X_val_with)), \n",
        "          torch.vstack((y_train_with, y_val_with)), \n",
        "          X_test_with, y_test_with, \n",
        "          n_epochs=ga_optimizer.population.best_indivdual.num_epochs_base)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Wws8akTKneKo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "fcf65dd1-cd0d-4f32-e960-769f04070e14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_ga_lstm_with, y_train, y_pred_test_ga_lstm_with, y_test = \\\n",
        "    get_predictions(ga_lstm_model, scaler_without, \n",
        "                    torch.vstack((X_train_with, X_val_with)),\n",
        "                    torch.vstack((y_train_with, y_val_with)), \n",
        "                    X_test_with, y_test_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "K5ZYf2cKneKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_ga_lstm_with, y_train, \n",
        "            y_pred_test_ga_lstm_with, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xpNhWpPQneKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4f4cc0-9a7b-4341-bd04-9bba150ee758"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'GA-LSTM-TI for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth')\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], y_pred_train_ga_lstm_with.ravel(), label='Train prediction')\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], y_pred_test_ga_lstm_with.ravel(), label='Test prediction', color='#9BB7D4')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "jZ3WHOVwneKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "7b5c2fbb-bd05-44bd-87f9-d1edfb8e5e18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GA-GRU"
      ],
      "metadata": {
        "id": "zDspDOU0wzfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "config = GeneticAlgorithmConfig(ell=150, k=40, num_epochs=10, mutation_rate=0.4)\n",
        "population = Population(config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iTKrsEv8wzfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer = GeneticAlgorithm(optimized_block='GRU',criterion=criterion, \n",
        "                                population=population, config=config, \n",
        "                                device=device, verbose=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9PdikJ0Xwzfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer.fit(X_val_without, y_val_without)"
      ],
      "outputs": [],
      "metadata": {
        "id": "f23Lt4qpwzfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "47bf4fe1-c80c-4f22-d5e1-744f01fcb26c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "ga_gru_model = GRU(input_size=X_train_without.shape[2],\n",
        "                    hidden_size=ga_optimizer.population.best_indivdual.hidden_size,\n",
        "                    num_layers=ga_optimizer.population.best_indivdual.num_layers)\n",
        "ga_gru_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "TzIKSMFGwzfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b01215f-79e3-42cf-9e34-fa238573e14c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(ga_gru_model.parameters(), \n",
        "                             lr=ga_optimizer.population.best_indivdual.learning_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "O0-bqeSTwzfv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_ga_gru_without, test_loss_ga_gru_without = \\\n",
        "    train(ga_gru_model, criterion, optimizer, device, \n",
        "          torch.vstack((X_train_without, X_val_without)), \n",
        "          torch.vstack((y_train_without, y_val_without)), \n",
        "          X_test_without, y_test_without,\n",
        "          n_epochs=ga_optimizer.population.best_indivdual.num_epochs_base)"
      ],
      "outputs": [],
      "metadata": {
        "id": "tedJw32Iwzfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "efb4357a-78ca-4be9-d82f-27274054aec0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_ga_gru_without, y_train, y_pred_test_ga_gru_without, y_test = \\\n",
        "    get_predictions(ga_gru_model, scaler_without, \n",
        "                    torch.vstack((X_train_without, X_val_without)),\n",
        "                    torch.vstack((y_train_without, y_val_without)), \n",
        "                    X_test_without, y_test_without)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7UxaE6fAwzfw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_ga_gru_without, y_train, \n",
        "            y_pred_test_ga_gru_without, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3c2IvDnJwzfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1893d360-78e1-4f99-a897-ce83e15bf8fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'GA-GRU for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth')\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_ga_gru_without.ravel(), \n",
        "         label='Train prediction')\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_ga_gru_without.ravel(), \n",
        "         label='Test prediction', color='#EDD59E')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "rGMrMc47wzfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "5e20489c-b8d1-4f3d-85a5-17b5ffc39988"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GA-GRU-TI"
      ],
      "metadata": {
        "id": "p0onZYMswzfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "config = GeneticAlgorithmConfig(ell=150, k=40, num_epochs=10, mutation_rate=0.4)\n",
        "population = Population(config)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VnGQRRdswzfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer = GeneticAlgorithm(optimized_block='GRU',criterion=criterion, \n",
        "                                population=population, config=config, \n",
        "                                device=device, verbose=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "3b2y90GYwzfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ga_optimizer.fit(X_val_with, y_val_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2QiVqGnGwzfx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "632492ba-a5e3-437b-aa78-78a8bd01b043"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "ga_gru_model = GRU(input_size=X_train_with.shape[2],\n",
        "                   hidden_size=ga_optimizer.population.best_indivdual.hidden_size,\n",
        "                   num_layers=ga_optimizer.population.best_indivdual.num_layers)\n",
        "ga_gru_model.to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bBI6CQG4wzfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2243245b-e773-4097-ed22-36ecf48b0c0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = torch.optim.Adam(ga_gru_model.parameters(), \n",
        "                             lr=ga_optimizer.population.best_indivdual.learning_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QXw47nILwzfy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed_everything()\n",
        "train_loss_ga_gru_with, test_loss_ga_gru_with = \\\n",
        "    train(ga_gru_model, criterion, optimizer, device,\n",
        "          torch.vstack((X_train_with, X_val_with)), \n",
        "          torch.vstack((y_train_with, y_val_with)), \n",
        "          X_test_with, y_test_with,\n",
        "          n_epochs=ga_optimizer.population.best_indivdual.num_epochs_base)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1ILSzM0Ewzfy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "64134c7a-bd85-44da-a13a-e219701b09e7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_pred_train_ga_gru_with, y_train, y_pred_test_ga_gru_with, y_test = \\\n",
        "    get_predictions(ga_gru_model, scaler_without, \n",
        "                    torch.vstack((X_train_with, X_val_with)),\n",
        "                    torch.vstack((y_train_with, y_val_with)), \n",
        "                    X_test_with, y_test_with)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mK9riN2twzfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "eval_losses(y_pred_train_ga_gru_with, y_train, \n",
        "            y_pred_test_ga_gru_with, y_test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1Vm6Fn9_wzfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63c3d82-acd0-4ff6-c08c-35161bf33c3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title(f'GA-GRU-TI for S&P500', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(df.index, df['Close'], label='Ground truth')\n",
        "\n",
        "plt.plot(df.index[window_size-1:val_size+train_size+window_size-1], \n",
        "         y_pred_train_ga_gru_with.ravel(), \n",
        "         label='Train prediction')\n",
        "\n",
        "plt.plot(df.index[val_size+train_size+window_size-1:], \n",
        "         y_pred_test_ga_gru_with.ravel(), \n",
        "         label='Test prediction', color='#6B5876')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.xlabel('Date', labelpad=10, fontsize=14)\n",
        "plt.ylabel('Closing price', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "jwnT2AQawzf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "1f2b7230-74c7-4a64-934c-a687980da328"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('Train RMSE', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(np.log(train_loss_ga_lstm_without), \n",
        "         marker='D', markersize=4, label='GA-LSTM', \n",
        "         alpha=0.7, color='#00A170')\n",
        "\n",
        "plt.plot(np.log(train_loss_ga_lstm_with), \n",
        "         marker='o', markersize=4, label='GA-LSTM-TI', \n",
        "         alpha=0.7, color='#9BB7D4')\n",
        "\n",
        "plt.plot(np.log(train_loss_ga_gru_without), \n",
        "         marker='^', markersize=4, label='GA-GRU', \n",
        "         alpha=0.7, color='#EDD59E')\n",
        "\n",
        "plt.plot(np.log(train_loss_ga_gru_with), \n",
        "         marker='s', markersize=4, label='GA-GRU-TI', \n",
        "         alpha=0.7, color='#6B5876')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel('Loss, log scaled', labelpad=10, fontsize=14)\n",
        "plt.xlabel('Epoch', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "mRE1gIabzWZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "0ace0398-a125-4aec-d421-741a933458f4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.title('Test RMSE', pad=14, fontsize=18, loc='left', fontweight='bold')\n",
        "\n",
        "plt.plot(np.log(test_loss_ga_lstm_without), \n",
        "         marker='D', markersize=4, label='GA-LSTM', \n",
        "\n",
        "         alpha=0.7, color='#00A170')\n",
        "plt.plot(np.log(test_loss_ga_lstm_with), \n",
        "         marker='o', markersize=4, label='GA-LSTM-TI', \n",
        "         alpha=0.7, color='#9BB7D4')\n",
        "\n",
        "plt.plot(np.log(test_loss_ga_gru_without), \n",
        "         marker='^', markersize=4, label='GA-GRU', \n",
        "         alpha=0.7, color='#EDD59E')\n",
        "\n",
        "plt.plot(np.log(test_loss_ga_gru_with), \n",
        "         marker='s', markersize=4, label='GA-GRU-TI', \n",
        "         alpha=0.7, color='#6B5876')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel('Loss, log scaled', labelpad=10, fontsize=14)\n",
        "plt.xlabel('Epoch', labelpad=10, fontsize=14);"
      ],
      "outputs": [],
      "metadata": {
        "id": "Oo_Tu5FgCG1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "a58c0f2b-3f72-4c42-e418-2d1948dd2739"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "FjOp7FmOs4WS"
      }
    }
  ]
}